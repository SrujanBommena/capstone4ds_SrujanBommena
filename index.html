<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>index</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="index_files/libs/clipboard/clipboard.min.js"></script>
<script src="index_files/libs/quarto-html/quarto.js"></script>
<script src="index_files/libs/quarto-html/popper.min.js"></script>
<script src="index_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="index_files/libs/quarto-html/anchor.min.js"></script>
<link href="index_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="index_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="index_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="index_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="index_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">




<section id="week-3---literature-review" class="level1">
<h1>WEEK 3 - LITERATURE REVIEW</h1>
<section id="machine-learning-algorithms-real-world-applications-and-research-directions" class="level2">
<h2 class="anchored" data-anchor-id="machine-learning-algorithms-real-world-applications-and-research-directions">Machine Learning: Algorithms, Real World Applications and Research Directions</h2>
<section id="background-motivation" class="level3">
<h3 class="anchored" data-anchor-id="background-motivation">BACKGROUND / MOTIVATION :</h3>
<section id="describe-the-context-in-which-the-research-was-conducted" class="level4">
<h4 class="anchored" data-anchor-id="describe-the-context-in-which-the-research-was-conducted">Describe the context in which the research was conducted</h4>
<p>Predictive process analytics is a rapidly growing field that uses machine learning to forecast future business processes, particularly in industries like healthcare, manufacturing, finance, and logistics. This helps optimize workflows and improve decision-making processes. However, as organizations adopt predictive analytics, the accuracy of these models has improved, but this has led to a loss of interpretability. This study is part of explainable artificial intelligence (XAI), which aims to make machine learning models more transparent. Without understanding the reasons behind predictions, stakeholders may hesitate to trust or act on them, leading to increased regulatory scrutiny in sectors like healthcare and finance, where decisions directly impact human lives.</p>
</section>
<section id="what-problem-or-gap-in-the-existing-literature-does-the-paper-aim-to-address" class="level4">
<h4 class="anchored" data-anchor-id="what-problem-or-gap-in-the-existing-literature-does-the-paper-aim-to-address">What problem or gap in the existing literature does the paper aim to address?</h4>
<p>This study aims to address the systematic evaluation of explainability techniques in predictive process analytics, which has been recognized as an open problem. While the literature is such that quite a number of papers exist that are concerned with the improving predictive models or proposing new XAI methods, no standard evaluation frameworks have been developed to evaluate the methods in terms of reliability, stability, and fidelity. This study develops functionally-grounded evaluation metrics for measuring stability and fidelity of explanations produced by some of the popular XAI methods, namely LIME and SHAP, as well as checks whether these methods deliver consistent and faithful explanations for predictive process models constructed using XGBoost, a widely employed machine learning algorithm known for its high classification accuracy.</p>
</section>
<section id="significance-of-research-question" class="level4">
<h4 class="anchored" data-anchor-id="significance-of-research-question">SIGNIFICANCE OF RESEARCH QUESTION</h4>
<p>A Guided Investigation into LIME and SHAP Explainability in Process Analytics - Reviewed for the effectiveness of predictive models’ explanations. - Benefited the reliability of explainability methods undertaken by organizations. - Promoted trust in machine learning-enabled decision-making. - Provided a potential agenda for future research in XAI.</p>
</section>
</section>
<section id="methods-used" class="level3">
<h3 class="anchored" data-anchor-id="methods-used">METHODS USED</h3>
<section id="methodologies-employed-and-how-these-methods-are-suited-to-address-the-research-question." class="level4">
<h4 class="anchored" data-anchor-id="methodologies-employed-and-how-these-methods-are-suited-to-address-the-research-question.">Methodologies employed and how these methods are suited to address the research question.</h4>
<p>Two properties, namely stability and fidelity, are assessed in this study by means of functionally grounded evaluation metrics. These metrics are calculated using predictive process models trained with XGBoost and are then conducted on three real-world event log datasets. The processes employed include:</p>
</section>
<section id="model-training" class="level4">
<h4 class="anchored" data-anchor-id="model-training">Model Training:</h4>
<p>XGBoost models are trained on three real-world event log datasets that capture business process execution data.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/w4.png" class="img-fluid figure-img" width="600"></p>
<figcaption>image</figcaption>
</figure>
</div>
</section>
<section id="explanation-generation" class="level4">
<h4 class="anchored" data-anchor-id="explanation-generation">Explanation Generation:</h4>
<p>LIME and SHAP explain the predictions made by the trained XGBoost models.</p>
</section>
<section id="stability-assessment" class="level4">
<h4 class="anchored" data-anchor-id="stability-assessment">Stability Assessment:</h4>
<p>Stability is assessed by generating explanations for similar instances and measuring how consistently the explanations remain.</p>
<p><span class="math display">\[ \[
Z = 1 - \frac{1}{d} P_d \sum_{i=1}^{s^2} f_i^k d \left(1 - \frac{k}{d} \right)
\]
\]</span></p>
<p>where; - <strong>d</strong> = Number of features encoded from event attributes in the log<br>
- <strong>M</strong> = Number of explanations generated for the process instance<br>
- <strong>k</strong> = Number of most relevant features, where relevance or level of importance<br>
is determined by an explanation generated for the process instance<br>
- <strong>k</strong> = Average number of features selected across all <strong>M</strong> explanations for the<br>
process instance<br>
- <strong>s²_fi</strong> = Sample variance of the presence of feature <strong>fᵢ</strong> across all <strong>M</strong> explanations<br>
for the process instance<br>
- <strong>Z</strong> = Binary matrix of size <strong>M × d</strong>. Each row of the binary matrix represents<br>
a feature subset, where a <strong>1</strong> at the <em>i-th</em> position means feature <strong>fᵢ</strong> has been<br>
selected and a <strong>0</strong> means it has not been selected.</p>
</section>
<section id="fidelity-assessment" class="level4">
<h4 class="anchored" data-anchor-id="fidelity-assessment">Fidelity Assessment:</h4>
<p>Fidelity is evaluated by perturbing input features based on the explanation and observing how the corresponding predictions of the model change.</p>
<p>The fidelity (F) of the interpreter for a single process instance in an event log is defined as:</p>
<p><span class="math display">\[
\[
F = \frac{1}{|X_0|} \sum_{x \in X_0} \frac{|Y(x) - Y(x_0)|}{Y(x)}
\]
\]</span></p>
<p>Where:<br>
- ( x ) = Original feature vector for the process instance. - ( X_0 ) = Set of perturbations for ( x ) and ( x_0 X_0 ) - ( Y(x) ) = Prediction probability given input ( x ) - ( Y(x_0) ) = Prediction probability given input ( x_0 )</p>
<p>This measure is naturally bounded by the fact that prediction probabilities<br>
fall between 0 and 1.</p>
</section>
<section id="discuss-any-innovative-approaches-or-techniques-that-are-particularly-noteworthy." class="level4">
<h4 class="anchored" data-anchor-id="discuss-any-innovative-approaches-or-techniques-that-are-particularly-noteworthy.">Discuss any innovative approaches or techniques that are particularly noteworthy.</h4>
<p>The study uses the functionally-grounded evaluation approach to assess the quality of explanations generated by LIME and SHAP. Stability and fidelity are crucial for building trust in machine learning models, while the study introduces specific perturbation techniques for event log data. This innovative approach adapts functionally-grounded evaluation metrics to predictive process analytics, ensuring that the methodology is well-suited to the characteristics of business process datasets. This approach is particularly useful for comparing reliable and misleading explanations. The study’s innovative approach and techniques contribute to the field’s advancements.</p>
</section>
</section>
<section id="significance-of-the-work" class="level3">
<h3 class="anchored" data-anchor-id="significance-of-the-work">SIGNIFICANCE OF THE WORK</h3>
<section id="highlight-the-key-findings-and-contributions-of-the-paper." class="level4">
<h4 class="anchored" data-anchor-id="highlight-the-key-findings-and-contributions-of-the-paper.">Highlight the key findings and contributions of the paper.</h4>
<p>Studies on XAI Methods for Predictive Process Analytics 1. SHAP is more stable than LIME because it makes sure that similar cases are explained the same way. 2. Both LIME and SHAP have reasonably moderate fidelity scores of use in explanations but do not always correspond to the reasoning provided by the model. 3. Preprocessing choices make a difference in the reliability of explanations, which would be recommended to be taken into consideration when it comes to predictive process analytics.</p>
</section>
<section id="explain-why-the-results-are-important-within-the-broader-context-of-the-field." class="level4">
<h4 class="anchored" data-anchor-id="explain-why-the-results-are-important-within-the-broader-context-of-the-field.">Explain why the results are important within the broader context of the field.</h4>
<p>These findings will have far-reaching implications for hydroponics in settings where the output, reasoning, and structure of predictive analytics must be explained. An interpretable AI diagnosis may boost the trust of healthcare professionals-diagnosticians in the system. In finance, AI-driven risk evaluation demands greater transparency from regulatory authorities on how the assessments are made. Addressing these issues by fostering the evaluative process of explainability methods assures the responsible adoption of AI in decision-making processes.</p>
</section>
<section id="discuss-the-implications-of-the-findings-for-future-research-or-practice" class="level4">
<h4 class="anchored" data-anchor-id="discuss-the-implications-of-the-findings-for-future-research-or-practice">Discuss the implications of the findings for future research or practice</h4>
<p>Predictive process analytics uses machine learning models to predict future process behavior, but their decision-making process can be difficult for humans to understand. This research aims to develop explainable artificial intelligence (XAI) methods specifically tailored for predictive process analytics, aiming to explain not only the model’s predictions but also how different features influence them in a process context. Hybrid explainability approaches combine multiple techniques to improve the quality and reliability of AI explanations. For example, a hybrid approach could combine local explanation methods like LIME with global methods like SHAP, providing detailed and generalizable insights into a model’s behavior. Research could also investigate the reliability of explanation methods across different machine learning algorithms, helping to identify the most effective XAI techniques for specific models and use cases.</p>
</section>
</section>
<section id="connection-to-other-work" class="level3">
<h3 class="anchored" data-anchor-id="connection-to-other-work">CONNECTION TO OTHER WORK</h3>
<section id="relate-the-paper-to-other-relevant-studies" class="level4">
<h4 class="anchored" data-anchor-id="relate-the-paper-to-other-relevant-studies">Relate the paper to other relevant studies</h4>
<ul>
<li>Research mainly products process monitoring with a particular focus on process-aware AI models and explainable dashboards.</li>
<li>Updates existing work on LIME and SHAP, evaluating the reliability of the approaches in the context of predictive analytics.</li>
<li>Develops toward more general XAI frameworks, focused on fidelity-and-stability assessment.</li>
<li>Extends earlier work by critically examining the applied methods in the domain of XAI rather than merely implementing them.</li>
</ul>
</section>
<section id="how-does-this-paper-build-on-or-differ-from-previous-work" class="level4">
<h4 class="anchored" data-anchor-id="how-does-this-paper-build-on-or-differ-from-previous-work">How does this paper build on or differ from previous work?</h4>
<p>This paper critically evaluates the reliability of XAI methods, moving beyond performance benchmarks to examine consistency and accuracy. It introduces a structured functionally-grounded evaluation framework applicable across different datasets and model architectures, and investigates real-world datasets for relevance and applicability.</p>
</section>
<section id="identify-any-references-to-seminal-works-or-influential-papers-cited-by-the-authors." class="level4">
<h4 class="anchored" data-anchor-id="identify-any-references-to-seminal-works-or-influential-papers-cited-by-the-authors.">Identify any references to seminal works or influential papers cited by the authors.</h4>
<p>References classical sources on explainable AI, including Doshi-Velez and Kim (2017) on interpretable machine learning.</p>
<p>Invokes previous works on LIME and SHAP in predictive process analytics, particularly Ribeiro et al.&nbsp;(2016) and Lundberg &amp; Lee (2017).</p>
<p>Borrowed benchmark work on predictive process monitoring of Teinemaa et al.&nbsp;(2019).</p>
<p>Anchored by a broader background on Earth AI and machine learning to provide context and depth.</p>
</section>
</section>
<section id="relevance-to-capstone-project" class="level3">
<h3 class="anchored" data-anchor-id="relevance-to-capstone-project">RELEVANCE TO CAPSTONE PROJECT</h3>
<section id="discuss-how-the-content-of-the-paper-might-be-relevant-to-your-own-capstone-project." class="level4">
<h4 class="anchored" data-anchor-id="discuss-how-the-content-of-the-paper-might-be-relevant-to-your-own-capstone-project.">Discuss how the content of the paper might be relevant to your own capstone project.</h4>
<p>The core of the capstone deals with designing predictive models with historical data, directed essentially toward an explanation for the sake of transparency. The findings of the study may determine the best explanation method to be applied, while evaluation metrics functionally grounded can be adjusted for interpretability assessment. Trust and reliability are paramount in AI-assisted decision-making.</p>
</section>
<section id="identify-any-specific-methods-theories-or-findings-that-you-might-incorporate-into-your-project." class="level4">
<h4 class="anchored" data-anchor-id="identify-any-specific-methods-theories-or-findings-that-you-might-incorporate-into-your-project.">Identify any specific methods, theories, or findings that you might incorporate into your project.</h4>
<ol type="1">
<li><p>We suggest the use of SHAP for feature attribution, as it shows strong stability and fidelity.</p></li>
<li><p>Use stability and fidelity metrics to test the reliability of your explanations.</p></li>
<li><p>Use perturbation approaches to validate your model explanations.</p></li>
<li><p>Investigate how functionally grounded evaluation can be extended to additional learning algorithms beyond XGBoost.</p></li>
</ol>
</section>
<section id="highlight-any-potential-areas-where-your-capstone-could-expand-upon-or-diverge-from-the-papers-findings." class="level4">
<h4 class="anchored" data-anchor-id="highlight-any-potential-areas-where-your-capstone-could-expand-upon-or-diverge-from-the-papers-findings.">Highlight any potential areas where your capstone could expand upon or diverge from the paper’s findings.</h4>
<p>This paper discusses the potential of a project to evaluate the explainability of deep learning models using hybrid methods like LIME and SHAP, incorporating user feedback for real-world application evaluation, and exploring additional domain-specific interpretability measures tailored to the project’s dataset and objectives.</p>
</section>
</section>
<section id="references" class="level3">
<h3 class="anchored" data-anchor-id="references">REFERENCES</h3>
<p>Du, M., Liu, N., Yang, F., Ji, S., Hu, X.: On attribution of recurrent neural network predictions via additive decomposition. In: The World Wide Web Conference - WWW 19 (2019).(https://doi.org/10.1145/3308558.3313545)</p>
<p>Mehdiyev, N., Fettke, P.: Prescriptive Process Analytics with Deep Learning and Explainable Artificial Intelligence. In: ECIS 2020 Proceedings. Marrakech, Morocco (15-17 June 2020),(https://aisel.aisnet.org/cgi/viewcontent.cgi?article=1121&amp;context=ecis2020_rp)</p>
<div data-align="right">
<p>SRUJAN BOMMENA</p>
</div>
</section>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>